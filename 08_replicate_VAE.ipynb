{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "from metric_functions import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "twins_path = 'data/TwinsUK.xls'\n",
    "qmdiab_path = 'data/QMDiab.xls'\n",
    "aml_path ='data/AML.xls'\n",
    "schizo_path = 'data/Schizophrenia.xls'\n",
    "\n",
    "replications_path = 'results/replications/'\n",
    "pca_path = 'results/encodings/'\n",
    "\n",
    "# Load files\n",
    "twins_train_df = pd.read_excel(twins_path, sheet_name='Training Set')\n",
    "twins_test_df = pd.read_excel(twins_path, sheet_name='Testing Set')\n",
    "\n",
    "# NOTE: there is also a full_overlap_data version in the twins h5 file, but\n",
    "# here we are just concatenating the loaded train and test datasets, to\n",
    "# preserve sample order\n",
    "twins_full_data = pd.concat([twins_train_df, twins_test_df], ignore_index = True)\n",
    "\n",
    "print('Twins data shape:\\t'        + str(twins_full_data.shape))\n",
    "print('Twins train data shape:\\t'  + str(twins_train_df.shape))\n",
    "print('Twins test data shape:\\t'   + str(twins_test_df.shape))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load clinical data files\n",
    "\n",
    "qmdiab_data = pd.read_excel(qmdiab_path, sheet_name='Metabolite Data')\n",
    "qmdiab_anno = pd.read_excel(qmdiab_path, sheet_name='Sample Annotations')\n",
    "\n",
    "aml_data = pd.read_excel(aml_path, sheet_name='Metabolite Data')\n",
    "aml_anno = pd.read_excel(aml_path, sheet_name='Sample Annotations')\n",
    "\n",
    "schizo_data = pd.read_excel(schizo_path, sheet_name='Metabolite Data')\n",
    "schizo_anno = pd.read_excel(schizo_path, sheet_name='Sample Annotations')\n",
    "schizo_anno= schizo_anno.drop(schizo_data.index [ np.unique(np.where(np.isnan(schizo_data))[0]) ])\n",
    "schizo_anno=schizo_anno.reset_index(drop=True)\n",
    "schizo_data= schizo_data.drop(schizo_data.index [ np.unique(np.where(np.isnan(schizo_data))[0]) ])\n",
    "schizo_data=schizo_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_k_pca_encoding(data, data_anno, path_pca, path_cosine, path_sigmoid, path_rbf, path_poly, latent_dim):\n",
    "    ######################\n",
    "    # Define PCA model\n",
    "    ######################\n",
    "    PCA_model_ = PCA_model(twins_train_df.values, latent_dim)\n",
    "\n",
    "    ######################\n",
    "    # Define KPCA models\n",
    "    ######################\n",
    "    KPCA_cosine_model_ = KPCA_model(twins_train_df.values, latent_dim, \"cosine\", 1, 0, 0, 0)\n",
    "    KPCA_sigmoid_model_ = KPCA_model(twins_train_df.values, latent_dim, \"sigmoid\", 1, 0.05, 0, 0)\n",
    "    KPCA_rbf_model_ = KPCA_model(twins_train_df.values, latent_dim, \"rbf\", 1, 0.005, 0, 0)\n",
    "    KPCA_poly_model_ = KPCA_model(twins_train_df.values, latent_dim, \"poly\", 2, 0.001, 3, 5.0)\n",
    "\n",
    "    pca_enc = PCA_model_.encode(data)\n",
    "    pca_enc = pd.DataFrame(pca_enc)\n",
    "    pca_enc = pd.concat([data_anno, pca_enc], axis = 1)\n",
    "    # Dimensions start at 0 (form python index 0). Add\n",
    "    # 1 to each dimension name to start with Dimension 1\n",
    "    pca_enc = pca_enc.rename(columns={i : i+1 for i in range(latent_dim)})\n",
    "    pca_enc.to_csv(path_pca, index = False)\n",
    "    \n",
    "    kpca_cosine_enc = KPCA_cosine_model_.encode(data)\n",
    "    kpca_cosine_enc = pd.DataFrame(kpca_cosine_enc)\n",
    "    kpca_cosine_enc = pd.concat([data_anno, kpca_cosine_enc], axis = 1)\n",
    "    # Dimensions start at 0 (form python index 0). Add\n",
    "    # 1 to each dimension name to start with Dimension 1\n",
    "    kpca_cosine_enc = kpca_cosine_enc.rename(columns={i : i+1 for i in range(latent_dim)})\n",
    "    kpca_cosine_enc.to_csv(path_cosine, index = False)\n",
    "    \n",
    "    kpca_sigmoid_enc = KPCA_sigmoid_model_.encode(data)\n",
    "    kpca_sigmoid_enc = pd.DataFrame(kpca_sigmoid_enc)\n",
    "    kpca_sigmoid_enc = pd.concat([data_anno, kpca_sigmoid_enc], axis = 1)\n",
    "    # Dimensions start at 0 (form python index 0). Add\n",
    "    # 1 to each dimension name to start with Dimension 1\n",
    "    kpca_sigmoid_enc = kpca_sigmoid_enc.rename(columns={i : i+1 for i in range(latent_dim)})\n",
    "    kpca_sigmoid_enc.to_csv(path_sigmoid, index = False)\n",
    "    \n",
    "    kpca_rbf_enc = KPCA_rbf_model_.encode(data)\n",
    "    kpca_rbf_enc = pd.DataFrame(kpca_rbf_enc)\n",
    "    kpca_rbf_enc = pd.concat([data_anno, kpca_rbf_enc], axis = 1)\n",
    "    # Dimensions start at 0 (form python index 0). Add\n",
    "    # 1 to each dimension name to start with Dimension 1\n",
    "    kpca_rbf_enc = kpca_rbf_enc.rename(columns={i : i+1 for i in range(latent_dim)})\n",
    "    kpca_rbf_enc.to_csv(path_rbf, index = False)\n",
    "    \n",
    "    kpca_poly_enc = KPCA_poly_model_.encode(data)\n",
    "    kpca_poly_enc = pd.DataFrame(kpca_poly_enc)\n",
    "    kpca_poly_enc = pd.concat([data_anno, kpca_poly_enc], axis = 1)\n",
    "    # Dimensions start at 0 (form python index 0). Add\n",
    "    # 1 to each dimension name to start with Dimension 1\n",
    "    kpca_poly_enc = kpca_poly_enc.rename(columns={i : i+1 for i in range(latent_dim)})\n",
    "    kpca_poly_enc.to_csv(path_poly, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data & model configuration\n",
    "\n",
    "def encode_k_pca(latent_dims, path):\n",
    "    for latent_dim in latent_dims:\n",
    "                \n",
    "        # Save paths for encoded data\n",
    "        qm_pca_encoding = path + 'QMDiab_PCA_encoding_d' + str(latent_dim)+'.csv'\n",
    "        qm_kpca_cosine_encoding = path + 'QMDiab_KPCA_cosine_encoding_d' + str(latent_dim)+'.csv'\n",
    "        qm_kpca_sigmoid_encoding = path + 'QMDiab_KPCA_sigmoid_encoding_d' + str(latent_dim)+'.csv'\n",
    "        qm_kpca_rbf_encoding = path + 'QMDiab_KPCA_rbf_encoding_d' + str(latent_dim)+'.csv'\n",
    "        qm_kpca_poly_encoding = path + 'QMDiab_KPCA_poly_encoding_d' + str(latent_dim)+'.csv'\n",
    "        save_k_pca_encoding(qmdiab_data, qmdiab_anno, qm_pca_encoding, qm_kpca_cosine_encoding, qm_kpca_sigmoid_encoding, qm_kpca_rbf_encoding, qm_kpca_poly_encoding, latent_dim)\n",
    "\n",
    "        \n",
    "        aml_pca_encoding = path + 'AML_PCA_encoding_d' + str(latent_dim)+'.csv'\n",
    "        aml_kpca_cosine_encoding = path + 'AML_KPCA_cosine_encoding_d' + str(latent_dim)+'.csv'\n",
    "        aml_kpca_sigmoid_encoding = path + 'AML_KPCA_sigmoid_encoding_d' + str(latent_dim)+'.csv'\n",
    "        aml_kpca_rbf_encoding = path + 'AML_KPCA_rbf_encoding_d' + str(latent_dim)+'.csv'\n",
    "        aml_kpca_poly_encoding = path + 'AML_KPCA_poly_encoding_d' + str(latent_dim)+'.csv'\n",
    "        save_k_pca_encoding(aml_data, aml_anno, aml_pca_encoding, aml_kpca_cosine_encoding, aml_kpca_sigmoid_encoding, aml_kpca_rbf_encoding, aml_kpca_poly_encoding, latent_dim)\n",
    "\n",
    "        \n",
    "        schizo_pca_encoding = path + 'Schizo_PCA_encoding_d' + str(latent_dim)+'.csv'\n",
    "        schizo_kpca_cosine_encoding = path + 'Schizo_KPCA_cosine_encoding_d' + str(latent_dim)+'.csv'\n",
    "        schizo_kpca_sigmoid_encoding = path + 'Schizo_KPCA_sigmoid_encoding_d' + str(latent_dim)+'.csv'\n",
    "        schizo_kpca_rbf_encoding = path + 'Schizo_KPCA_rbf_encoding_d' + str(latent_dim)+'.csv'\n",
    "        schizo_kpca_poly_encoding = path + 'Schizo_KPCA_poly_encoding_d' + str(latent_dim)+'.csv'\n",
    "        save_k_pca_encoding(schizo_data, schizo_anno, schizo_pca_encoding, schizo_kpca_cosine_encoding, schizo_kpca_sigmoid_encoding, schizo_kpca_rbf_encoding, schizo_kpca_poly_encoding,latent_dim)\n",
    "        \n",
    "\n",
    "def replicate_VAE(i, latent_dims, path):\n",
    "    input_dim = twins_train_df.shape[1]\n",
    "    intermediate_dim = 150\n",
    "    kl_beta = 0.1\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    batch_size = 32\n",
    "    n_epochs = 1000\n",
    "\n",
    "    # Loop over replicate number\n",
    "    # Train a VAE for each latent dimension\n",
    "    for latent_dim in latent_dims:\n",
    "        # instantiate model\n",
    "        mtmodel = mtVAE(input_dim,\n",
    "                        intermediate_dim,\n",
    "                        latent_dim,\n",
    "                        kl_beta,\n",
    "                        learning_rate)\n",
    "\n",
    "        # Train model\n",
    "        mtmodel.train(twins_train_df, twins_test_df, n_epochs, batch_size)\n",
    "        \n",
    "        # Save QMDiab encoding\n",
    "        path_vae = path + 'QMDiab_VAE_encoding_'+str(latent_dim)+'_'+str(i)+'.csv'\n",
    "        vae_enc = mtmodel.encode_mu(qmdiab_data.values)\n",
    "        vae_enc = pd.DataFrame(vae_enc)\n",
    "        vae_enc = pd.concat([qmdiab_anno, vae_enc], axis = 1)\n",
    "        # rename dimension 0 to latent dimension\n",
    "        vae_enc = vae_enc.rename(columns={0: latent_dim})\n",
    "        #  move last dimension to the last column\n",
    "        vae_enc = vae_enc[ [ col for col in vae_enc.columns if col != latent_dim ] + [latent_dim] ]\n",
    "        vae_enc.to_csv(path_vae, index = False)\n",
    "        \n",
    "        # Save AML encoding\n",
    "        path_vae = path + 'AML_VAE_encoding_'+str(latent_dim)+'_'+str(i)+'.csv'\n",
    "        vae_enc = mtmodel.encode_mu(aml_data.values)\n",
    "        vae_enc = pd.DataFrame(vae_enc)\n",
    "        vae_enc = pd.concat([aml_anno, vae_enc], axis = 1)\n",
    "        # rename dimension 0 to latent dimension\n",
    "        vae_enc = vae_enc.rename(columns={0: latent_dim})\n",
    "        #  move last dimension to the last column\n",
    "        vae_enc = vae_enc[ [ col for col in vae_enc.columns if col != latent_dim ] + [latent_dim] ]\n",
    "        vae_enc.to_csv(path_vae, index = False)\n",
    "\n",
    "        # Save Schizo encoding\n",
    "        path_vae = path + 'Schizo_VAE_encoding_'+str(latent_dim)+'_'+str(i)+'.csv'\n",
    "        vae_enc = mtmodel.encode_mu(schizo_data.values)\n",
    "        vae_enc = pd.DataFrame(vae_enc)\n",
    "        vae_enc = pd.concat([schizo_anno, vae_enc], axis = 1)\n",
    "        # rename dimension 0 to latent dimension\n",
    "        vae_enc = vae_enc.rename(columns={0: latent_dim})\n",
    "        #  move last dimension to the last column\n",
    "        vae_enc = vae_enc[ [ col for col in vae_enc.columns if col != latent_dim ] + [latent_dim] ]\n",
    "        vae_enc.to_csv(path_vae, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "replications = 1000\n",
    "latent_dims = [10, 13, 15, 16, 17, 18, 20]\n",
    "\n",
    "encode_k_pca(latent_dims, pca_path)\n",
    "\n",
    "for i in range(replications):\n",
    "    replicate_VAE(i, latent_dims, replications_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}